{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b45bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "# Import necessary libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Read the 'big.txt' file, which presumably contains text data\n",
    "with open('big.txt', 'r') as fd:\n",
    "    lines = fd.readlines()\n",
    "    words = []\n",
    "    \n",
    "    # Tokenize the text by extracting words (alphanumeric sequences) and converting them to lowercase\n",
    "    for line in lines:\n",
    "        words += re.findall('\\w+', line.lower())\n",
    "\n",
    "# Function to find N-grams\n",
    "def get_pairs(words, n):\n",
    "    # Increment N by 1 to create N-grams\n",
    "    n = n + 1\n",
    "    data = []\n",
    "    \n",
    "    # Loop through the words to extract N-grams\n",
    "    for i in range(len(words) - n):\n",
    "        data.append(' '.join(words[i:i + n]))\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Function to calculate occurrence probabilities\n",
    "def get_prob_dist(data):\n",
    "    a = np.array(data)\n",
    "    \n",
    "    # Find unique N-grams and their counts using NumPy\n",
    "    pair, count = np.unique(a, return_counts=True)\n",
    "    unique_pairs = list(set(data))\n",
    "    \n",
    "    prob_dist = []\n",
    "    \n",
    "    # Create a list of N-gram, preceding words, following word, and frequency\n",
    "    for i in range(len(unique_pairs)):\n",
    "        prob_dist.append([unique_pairs[i], ' '.join(unique_pairs[i].split(' ')[:-1]), unique_pairs[i].split(' ')[-1], count[i]])\n",
    "    \n",
    "    return prob_dist\n",
    "\n",
    "# Generate N-grams (four-grams in this case)\n",
    "data = get_pairs(words, 4)\n",
    "\n",
    "# Calculate occurrence probabilities for the N-grams\n",
    "prob_dist = get_prob_dist(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aaa35e",
   "metadata": {},
   "source": [
    "### Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79ee994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq is not present\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'of the united states demanded the immediate ratification of the treaty the democrats and populists took exception in the senate where southern interests were intrenched then after the senate was won over a democratic president james buchanan vetoed the bill still the issue lived the republicans strong among the farmers of the northwest favored'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_pairs(words, 4)\n",
    "prob_dist = get_prob_dist(data)\n",
    "\n",
    "# Create a DataFrame to store the word pairs and their frequencies\n",
    "df = pd.DataFrame(prob_dist, columns=['seq', 'inp', 'out', 'freq'])\n",
    "\n",
    "# Function to predict next word based on an input sequence\n",
    "def predict(word):\n",
    "    if len(df[df['inp'] == word]):\n",
    "        # Filter DataFrame to find matching input sequences\n",
    "        df_ = df[df['inp'] == word]\n",
    "        # Sort by frequency and take the top results, then retrieve the 'out' values\n",
    "        return df_.sort_values(by='freq').head()['out'].values\n",
    "    else:\n",
    "        print('Seq is not present')\n",
    "\n",
    "# Predict the next word for the given input sequence\n",
    "predict('this is a beautiful')\n",
    "\n",
    "# Predict the next word for another input sequence\n",
    "predict('the is a beautiful')\n",
    "\n",
    "# Function to predict the next 'n' words in a sequence\n",
    "def pred_seq(seq, n):\n",
    "    output = []\n",
    "    output.append(seq)\n",
    "\n",
    "    for i in range(n):\n",
    "        pred = predict(seq)\n",
    "        # Update the input sequence by removing the first word and adding the predicted word\n",
    "        seq = ' '.join(seq.split(' ')[1:]) + ' ' + pred[0]\n",
    "        output.append(pred[0])\n",
    "\n",
    "    return ' '.join(output)\n",
    "\n",
    "# Predict the next 50 words in a sequence starting with 'of the united states'\n",
    "pred_seq('of the united states', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe1497",
   "metadata": {},
   "source": [
    "### Context word Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a122963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>left_seq</th>\n",
       "      <th>right_seq</th>\n",
       "      <th>output</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 05 grm novarsenbillon</td>\n",
       "      <td>0 05</td>\n",
       "      <td>novarsenbillon</td>\n",
       "      <td>grm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 25 u and</td>\n",
       "      <td>0 25</td>\n",
       "      <td>and</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 45 grm given</td>\n",
       "      <td>0 45</td>\n",
       "      <td>given</td>\n",
       "      <td>grm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 5 to 2</td>\n",
       "      <td>0 5</td>\n",
       "      <td>2</td>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 6 grm all</td>\n",
       "      <td>0 6</td>\n",
       "      <td>all</td>\n",
       "      <td>grm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       seq left_seq       right_seq output  freq\n",
       "0  0 05 grm novarsenbillon     0 05  novarsenbillon    grm     1\n",
       "1               0 25 u and     0 25             and      u     1\n",
       "2           0 45 grm given     0 45           given    grm     1\n",
       "3                 0 5 to 2      0 5               2     to     1\n",
       "4              0 6 grm all      0 6             all    grm     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prob_dist(data):\n",
    "    # Initialize an empty list to store probability distribution data\n",
    "    prob_dist = []    \n",
    "    # Convert input data to a NumPy array\n",
    "    a = np.array(data)\n",
    "    # Find unique pairs and their counts from the input data\n",
    "    pairs, counts = np.unique(a, return_counts = True)\n",
    "    \n",
    "    # Iterate through each unique pair\n",
    "    for i in range(len(pairs)):\n",
    "        \n",
    "        # Extract left, right, and middle sequences from the pair\n",
    "        left_seq   = ' '.join(pairs[i].split(' ')[:len(pairs[i].split(' '))//2])\n",
    "        right_seq  = ' '.join(pairs[i].split(' ')[len(pairs[i].split(' '))//2 + 1: ])\n",
    "        middle_seq = pairs[i].split(' ')[len(pairs[i].split(' '))//2]\n",
    "        \n",
    "        # Store the pair and its components along with frequency in the probability distribution list\n",
    "        prob_dist.append([pairs[i],left_seq, right_seq, middle_seq, counts[i]])\n",
    "        \n",
    "    return prob_dist\n",
    "        \n",
    "# Generate sequences of three words (3-grams)   \n",
    "data = get_pairs(words,3)\n",
    "# Calculate probability distribution of the generated sequences\n",
    "prob_dist = get_prob_dist(data)\n",
    "# Create a DataFrame from the probability distribution data\n",
    "df = pd.DataFrame(prob_dist, columns = ['seq','left_seq','right_seq','output','freq'])\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f4fb967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(word):\n",
    "    # Split the input word into left and right sequences\n",
    "    left_seq = word.split('_')[0].strip()\n",
    "    right_seq = word.split('_')[1].strip()\n",
    "\n",
    "    # Filter the DataFrame to find matches for the left and right sequences\n",
    "    df_ = df[df['left_seq'] == left_seq]\n",
    "    df_ = df_[df_['right_seq'] == right_seq]\n",
    "\n",
    "    # Sort the matches by frequency in descending order and extract the top outputs\n",
    "    return list(df_.sort_values(by='freq', ascending=False).head()['output'].values)\n",
    "\n",
    "# Predict words based on the given left and right sequences\n",
    "predict('the _ states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407e27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
